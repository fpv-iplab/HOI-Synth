# Are Synthetic Data Useful for Egocentric Hand-Object Interaction Detection?
## Overview
[Project Page](https://fpv-iplab.github.io/HOI-Synth/) - [Paper](https://arxiv.org/pdf/2312.02672)

## Updates
* 01/07/2024: **Accepted at European Conference on Computer Vision (ECCV) 2024!** <br>

## Citation
If you use our HOI-Synth benchmark, data generation pipeline or this code for your research, please cite our paper:
```
@article{leonardi2023synthetic,
  title={Are Synthetic Data Useful for Egocentric Hand-Object Interaction Detection? An Investigation and the HOI-Synth Domain Adaptation Benchmark},
  author={Leonardi, Rosario and Furnari, Antonino and Ragusa, Francesco and Farinella, Giovanni Maria},
  journal={arXiv preprint arXiv:2312.02672},
  year={2023}
}
```

## Table of Contents
1. [HOI-Synth benchmark](#hoi-synth-benchmark)
2. [Data Generation Pipeline](#data-generation-pipeline)
3. [Baselines](#baselines)
4. [License](#license)
5. [Ackowledgements](#ackowledgements)<br>


## HOI-Synth benchmark
The HOI-Synth benchmark extends three established datasets of egocentric images designed to study hand-object interaction detection, EPIC-KITCHENS VISOR [1], EgoHOS [2], and ENIGMA-51 [3], with automatically labeled synthetic data obtained through the proposed HOI generation pipeline.

### Download

#### Synthetic-Data
You can download the synthetic dataset at the following [link](link).

#### EPIC-KITCHENS VISOR
https://github.com/epic-kitchens/VISOR-HOS?tab=readme-ov-file

#### EgoHOS
https://github.com/owenzlz/EgoHOS

#### ENIGMA-51
https://iplab.dmi.unict.it/ENIGMA-51/

## Data Generation Pipeline
Coming soon!

## Baselines 
Coming soon!

## License

## Ackowledgements
This research has been supported by the project Future Artificial Intelligence Research (FAIR) – PNRR MUR Cod. PE0000013 - CUP: E63C22001940006 <br>
This research has been partially supported by the project EXTRA-EYE - PRIN 2022 - CUP E53D23008280006 - Finanziato dall’Unione Europea - Next Generation EU 

## References

* [1] Darkhalil, A., Shan, D., Zhu, B., Ma, J., Kar, A., Higgins, R., Fidler, S., Fouhey, D., Damen, D.: Epic-kitchens visor benchmark: Video segmentations and object relations. In: NeurIPS. pp. 13745–13758 (2022)
* [2] Zhang, L., Zhou, S., Stent, S., Shi, J.: Fine-grained egocentric hand-object segmentation: Dataset, model, and applications. In: ECCV. pp. 127–145 (2022)
* [3] Ragusa, F., Leonardi, R., Mazzamuto, M., Bonanno, C., Scavo, R., Furnari, A., & Farinella, G. M.: ENIGMA-51: Towards a Fine-Grained Understanding of Human Behavior in Industrial Scenarios. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (pp. 4549-4559) (2024)